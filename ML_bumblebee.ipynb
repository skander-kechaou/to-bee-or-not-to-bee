{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd3a9d3",
   "metadata": {},
   "source": [
    "# Machine Learning Project : To bee or not to bee\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe442a3",
   "metadata": {},
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07368108",
   "metadata": {},
   "source": [
    "* Context : Pollinator insects such as bees and bumblebees are important for ecosystems diversity and by fertilizing flowers, they play a vital role in the global food chain system.\n",
    "* Problem : Distinguishing bee types amongst pollinators is crucial in this context and traditional methods which are mostly manual are quite time-consuming especially with our dataset of 250 images, although it might be less prone to error\n",
    "* Solution : This project aims to leverage Machine Learning (ML), Deep Learning and Ai & Optimization techniques to automate the identification process by looking at an image (and its mask) and recognize the bug type and in a later time its species.\n",
    "* Stakeholders : This project would interest more than one amongst researches, within the agricultural sector as well as for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce7b64",
   "metadata": {},
   "source": [
    "Now that we're well versed in the subject of this project we can get into the technicalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adca6cc",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78f79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import the necessary libraries \n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.optimize import minimize\n",
    "import scipy.ndimage as ndi\n",
    "import datetime\n",
    "from time import process_time\n",
    "import glob\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06feb31",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc61936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'tobeeornottobee_train_v2/train' \n",
    "MASK_FOLDER = 'tobeeornottobee_train_v2/train/masks'  \n",
    "MASK_FILE_EXTENSION = '.tif'\n",
    "EXPECTED_TRAINING_FILES = 250\n",
    "LABELS_PATH = 'tobeeornottobee_train_v2/train/classif.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c0c6e",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a4999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the 250 files based on sorted filenames.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e023c5b3644c2ebf75b6fc8afebffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not read mask file: 'tobeeornottobee_train_v2/train/masks\\binary_154.tif'. Skipping this pair.\n",
      "\n",
      "Finished loading. Successfully loaded 249 image/mask pairs.\n"
     ]
    }
   ],
   "source": [
    "training_data = [] # we will store each image and its mask identified by a unique ID (seq(0,250))\n",
    "\n",
    "try:\n",
    "    # list the files in IMAGE_FOLDER.\n",
    "    all_files_in_image_folder = os.listdir(IMAGE_FOLDER)\n",
    "\n",
    "    # keep only the .jpg files (filter out the /mask folder)\n",
    "    image_filenames = [f for f in all_files_in_image_folder if f.lower().endswith('.jpg')]\n",
    "\n",
    "    # sort the filenames numerically \n",
    "    # since our files aren't formatted such as 001, 002 if we keep them this way 100 will be before 2 \n",
    "    def sort_key(filename):\n",
    "        match = re.match(r'(\\d+)\\.jpg', filename, re.IGNORECASE) # find number (digits) before the extension\n",
    "        return int(match.group(1))\n",
    "    image_filenames.sort(key=sort_key)\n",
    "\n",
    "    # make sure we have 250 files loaded so far\n",
    "    files_to_load = image_filenames[:EXPECTED_TRAINING_FILES]\n",
    "    if len(files_to_load) < EXPECTED_TRAINING_FILES:\n",
    "         print(f\"Warning: Loading {len(files_to_load)} files.\")\n",
    "    else:\n",
    "         print(f\"Loading the {len(files_to_load)} files based on sorted filenames.\")\n",
    "\n",
    "    for img_filename in tqdm(files_to_load, desc=\"Processing Files\"):\n",
    "\n",
    "        # getting the name that will serve as ID as well\n",
    "        image_id = os.path.splitext(img_filename)[0]\n",
    "\n",
    "        # creating full path to the image file\n",
    "        image_path = os.path.join(IMAGE_FOLDER, img_filename)\n",
    "\n",
    "        # finding expected filename for the corresponding mask.\n",
    "        mask_filename = \"binary_\" + image_id + MASK_FILE_EXTENSION # e.g., \"binary_1.tif\"\n",
    "        # creating full path to the mask file\n",
    "        mask_path = os.path.join(MASK_FOLDER, mask_filename)\n",
    "        \n",
    "        # load the image using OpenCV (BGR format by default in OpenCV)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"  Warning: Could not read image file: '{image_path}'. Skipping this pair.\") # check if loading works\n",
    "            continue \n",
    "\n",
    "        # load the mask as Grayscale (single channel) using OpenCV\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"  Warning: Could not read mask file: '{mask_path}'. Skipping this pair.\") # check if loading worked.\n",
    "            continue\n",
    "\n",
    "        # finallt, store the loaded data in our list.\n",
    "        data_item = {\n",
    "            'id': image_id,        # The identifier (e.g., '1', '123')\n",
    "            'image': image,        # The loaded image \n",
    "            'mask': mask           # The loaded mask (corresponding to the image)\n",
    "        }\n",
    "        training_data.append(data_item)\n",
    "\n",
    "    print(f\"\\nFinished loading. Successfully loaded {len(training_data)} image/mask pairs.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error in paths\")\n",
    "    training_data = [] # Ensure data list is empty if loading failed\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred\")\n",
    "    print(e)\n",
    "    training_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1834e9e",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec70783",
   "metadata": {},
   "source": [
    "Defining helper functions derived from the AI & Optimization LAB \n",
    "\n",
    "However, We'll use ndi for rotation instead of matrixes to avoid time-consuming iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d51936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(theta_degree_scalar, xc, yc, binary_arr):\n",
    "    rotated_mask = ndi.rotate(binary_arr, angle=theta_degree_scalar, reshape=False, \n",
    "                              mode='constant', cval=0, order=0) # order=0 for binary\n",
    "    return (rotated_mask > 0.5).astype(np.uint8) # ensure binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3672e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_loss(theta_degree, xc, yc, binary_arr): # xc, yc are for context\n",
    "    s1, s2 = binary_arr.shape\n",
    "\n",
    "    if isinstance(theta_degree, (np.ndarray, list, tuple)):\n",
    "        current_theta = theta_degree[0] # Take the first element if it's an array/list\n",
    "    else:\n",
    "        current_theta = theta_degree    # Assume it's already a scalar\n",
    "\n",
    "    # using faster ndi-based rotation instead of LAB1 logic from AI & Optimization\n",
    "    rot_arr = rotate_image(current_theta, xc, yc, binary_arr) \n",
    "\n",
    "    [x_rot, y_rot] = np.where(rot_arr > 0)\n",
    "\n",
    "    if len(x_rot) == 0: # if rotated mask is empty\n",
    "        return float(s1 * s2) # max possible loss\n",
    "\n",
    "    min_r, max_r = np.min(x_rot), np.max(x_rot)\n",
    "    min_c, max_c = np.min(y_rot), np.max(y_rot)\n",
    "    \n",
    "    bb_rot_area = (max_r - min_r + 1) * (max_c - min_c + 1)\n",
    "    loss = float(bb_rot_area - np.sum(rot_arr)) # Area of bbox - area of rotated mask\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5f19d",
   "metadata": {},
   "source": [
    "Main logic for feature extraction to implement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d11e9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_id, image_rgb_arr_input, mask_binary_arr_input):\n",
    "    features = {'id': image_id}\n",
    "    boolean_mask = mask_binary_arr_input.astype(bool)\n",
    "    num_bug_pixels = np.sum(mask_binary_arr_input)\n",
    "    feature_names = [\n",
    "        'shape_eccentricity', 'shape_solidity', 'pixel_ratio_bug_to_total',\n",
    "        'R_min', 'R_max', 'R_mean', 'R_median', 'R_std',\n",
    "        'G_min', 'G_max', 'G_mean', 'G_median', 'G_std',\n",
    "        'B_min', 'B_max', 'B_mean', 'B_median', 'B_std',\n",
    "        'bug_area', 'bbox_aspect_ratio',\n",
    "        'centroid_x', 'centroid_y', \n",
    "        'optimal_angle', \n",
    "        'oriented_bbox_area', \n",
    "        'oriented_bbox_aspect_ratio', \n",
    "        'mask_area_to_oriented_bbox_area_ratio', \n",
    "        'hu_moment_1', 'hu_moment_2', \n",
    "        'contour_complexity_approx'\n",
    "    ]\n",
    "    for name in feature_names: features[name] = np.nan\n",
    "    features['pixel_ratio_bug_to_total'] = 0.0 \n",
    "    features['bug_area'] = 0\n",
    "    if num_bug_pixels == 0:\n",
    "        print(f\"Warning: Mask for image {image_id} is effectively empty.\")\n",
    "        return features \n",
    "    features['bug_area'] = num_bug_pixels\n",
    "    label_img_sk = measure.label(mask_binary_arr_input)\n",
    "    props_list_sk = measure.regionprops(label_img_sk, intensity_image=image_rgb_arr_input)\n",
    "    if props_list_sk:\n",
    "        bug_props_sk = props_list_sk[0]\n",
    "        features['shape_eccentricity'] = bug_props_sk.eccentricity\n",
    "        features['shape_solidity'] = bug_props_sk.solidity\n",
    "        minr, minc, maxr, maxc = bug_props_sk.bbox\n",
    "        bbox_height = maxr - minr \n",
    "        bbox_width = maxc - minc  \n",
    "        features['bbox_aspect_ratio'] = bbox_height / bbox_width if bbox_width > 0 else np.nan\n",
    "    total_pixels = image_rgb_arr_input.shape[0] * image_rgb_arr_input.shape[1]\n",
    "    if total_pixels > 0 :\n",
    "        features['pixel_ratio_bug_to_total'] = num_bug_pixels / total_pixels\n",
    "    for i, color_char in enumerate(['R', 'G', 'B']):\n",
    "        channel_pixels = image_rgb_arr_input[:, :, i][boolean_mask]\n",
    "        if channel_pixels.size > 0: \n",
    "            features[f'{color_char}_min'] = np.min(channel_pixels)\n",
    "            features[f'{color_char}_max'] = np.max(channel_pixels)\n",
    "            features[f'{color_char}_mean'] = np.mean(channel_pixels)\n",
    "            features[f'{color_char}_median'] = np.median(channel_pixels)\n",
    "            features[f'{color_char}_std'] = np.std(channel_pixels)\n",
    "    [rows, cols] = np.where(mask_binary_arr_input > 0)\n",
    "    xc_mask = np.mean(rows) \n",
    "    yc_mask = np.mean(cols)\n",
    "    features['centroid_x'] = xc_mask\n",
    "    features['centroid_y'] = yc_mask\n",
    "    try:\n",
    "        test_angles = np.arange(0, 181, 45) \n",
    "        losses = [bb_loss(angle, xc_mask, yc_mask, mask_binary_arr_input) for angle in test_angles]\n",
    "        initial_angle_guess = test_angles[np.argmin(losses)]\n",
    "        res = minimize(bb_loss, initial_angle_guess, \n",
    "                       args=(xc_mask, yc_mask, mask_binary_arr_input),\n",
    "                       method='Nelder-Mead', \n",
    "                       options={'xatol': 2e-1, 'fatol': 2e-1, 'maxiter': 10}) \n",
    "        current_optimal_angle = initial_angle_guess \n",
    "        if res.success or 'iteration limit' in res.message.lower() or 'tolerance' in res.message.lower():\n",
    "            # Ensure res.x[0] is scalar for optimal_angle\n",
    "            if isinstance(res.x, (np.ndarray, list, tuple)):\n",
    "                current_optimal_angle = res.x[0] % 180\n",
    "            else:\n",
    "                current_optimal_angle = res.x % 180\n",
    "\n",
    "        features['optimal_angle'] = current_optimal_angle\n",
    "        rot_arr_optimal = rotate_image(current_optimal_angle, xc_mask, yc_mask, mask_binary_arr_input)\n",
    "        [x_rot_opt, y_rot_opt] = np.where(rot_arr_optimal > 0)\n",
    "        if len(x_rot_opt) > 0:\n",
    "            min_r_opt, max_r_opt = np.min(x_rot_opt), np.max(x_rot_opt)\n",
    "            min_c_opt, max_c_opt = np.min(y_rot_opt), np.max(y_rot_opt)\n",
    "            oriented_bbox_h = max_r_opt - min_r_opt + 1 \n",
    "            oriented_bbox_w = max_c_opt - min_c_opt + 1 \n",
    "            obb_area = oriented_bbox_h * oriented_bbox_w\n",
    "            features['oriented_bbox_area'] = obb_area\n",
    "            features['oriented_bbox_aspect_ratio'] = oriented_bbox_h / oriented_bbox_w if oriented_bbox_w > 0 else np.nan\n",
    "            mask_area_in_oriented_bbox = np.sum(rot_arr_optimal)\n",
    "            if obb_area > 0:\n",
    "                features['mask_area_to_oriented_bbox_area_ratio'] = mask_area_in_oriented_bbox / obb_area\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Lab01-style optimization for {image_id}: {e}.\")\n",
    "    moments = cv2.moments(mask_binary_arr_input) \n",
    "    hu_moments = cv2.HuMoments(moments).flatten()\n",
    "    features['hu_moment_1'] = hu_moments[0] if len(hu_moments) > 0 else np.nan\n",
    "    features['hu_moment_2'] = hu_moments[1] if len(hu_moments) > 1 else np.nan\n",
    "    if props_list_sk: \n",
    "        contours, _ = cv2.findContours(mask_binary_arr_input.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "        if contours and len(contours) > 0: \n",
    "             main_contour = max(contours, key=cv2.contourArea) \n",
    "             if len(main_contour) > 1 : \n",
    "                 perimeter_cv = cv2.arcLength(main_contour, True)\n",
    "                 if perimeter_cv > 0:\n",
    "                     features['contour_complexity_approx'] = len(main_contour) / perimeter_cv\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b825f1",
   "metadata": {},
   "source": [
    "Feature extraction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting feature extraction for 249 items...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b8693091f345bebff0d71eee0866b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_extracted_features = []\n",
    "\n",
    "if training_data: # check if data was loaded successfully\n",
    "    print(f\"\\nStarting feature extraction for {len(training_data)} items...\")\n",
    "    for item in tqdm(training_data, desc=\"Extracting Features\"):\n",
    "        image_id_str = item['id']\n",
    "        image_bgr_arr = item['image']       \n",
    "        mask_grayscale_arr = item['mask']  \n",
    "\n",
    "        # BGR to RGB \n",
    "        image_rgb_for_function = cv2.cvtColor(image_bgr_arr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # binarize the grayscale mask\n",
    "        mask_binary_for_function = (mask_grayscale_arr > 0).astype(np.uint8)\n",
    "        \n",
    "        # Extract features using the prepared image and mask\n",
    "        features = extract_features(image_id_str, image_rgb_for_function, mask_binary_for_function)\n",
    "        \n",
    "        all_extracted_features.append(features)\n",
    "\n",
    "    if all_extracted_features: # check if any features were actually extracted\n",
    "        features_df = pd.DataFrame(all_extracted_features)\n",
    "\n",
    "        print(\"--- Extracted Features (First 5 rows) ---\")\n",
    "        print(features_df.head())\n",
    "\n",
    "        # in case i need to save to csv later features_df.to_csv(\"extracted_bee_project_features.csv\", index=False)\n",
    "    else:\n",
    "        print(\"No features were extracted\")\n",
    "\n",
    "else:\n",
    "    print(\"No data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e06b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
