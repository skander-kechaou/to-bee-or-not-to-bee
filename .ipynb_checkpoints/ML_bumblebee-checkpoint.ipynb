{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd3a9d3",
   "metadata": {},
   "source": [
    "# Machine Learning Project : To bee or not to bee\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe442a3",
   "metadata": {},
   "source": [
    "## 1. Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07368108",
   "metadata": {},
   "source": [
    "* Context : Pollinator insects such as bees and bumblebees are important for ecosystems diversity and by fertilizing flowers, they play a vital role in the global food chain system.\n",
    "* Problem : Distinguishing bee types amongst pollinators is crucial in this context and traditional methods which are mostly manual are quite time-consuming especially with our dataset of 250 images, although it might be less prone to error\n",
    "* Solution : This project aims to leverage Machine Learning (ML), Deep Learning and Ai & Optimization techniques to automate the identification process by looking at an image (and its mask) and recognize the bug type and in a later time its species.\n",
    "* Stakeholders : This project would interest more than one amongst researches, within the agricultural sector as well as for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce7b64",
   "metadata": {},
   "source": [
    "Now that we're well versed in the subject of this project we can get into the technicalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adca6cc",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b78f79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import the necessary libraries \n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.optimize import minimize\n",
    "import scipy.ndimage as ndi\n",
    "import datetime\n",
    "from time import process_time\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06feb31",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc61936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_FOLDER = 'tobeeornottobee_train_v2/train' \n",
    "MASK_FOLDER = 'tobeeornottobee_train_v2/train/masks'  \n",
    "MASK_FILE_EXTENSION = '.tif'\n",
    "EXPECTED_TRAINING_FILES = 250\n",
    "LABELS_PATH = 'tobeeornottobee_train_v2/train/classif.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7c0c6e",
   "metadata": {},
   "source": [
    "### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a4999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the 250 files based on sorted filenames.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4568fd4061264613bbd648d8910e51c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files:   0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Warning: Could not read mask file: 'tobeeornottobee_train_v2/train/masks\\binary_154.tif'. Skipping this pair.\n",
      "\n",
      "Finished loading. Successfully loaded 249 image/mask pairs.\n"
     ]
    }
   ],
   "source": [
    "training_data = [] # we will store each image and its mask identified by a unique ID (seq(0,250))\n",
    "\n",
    "try:\n",
    "    # list the files in IMAGE_FOLDER.\n",
    "    all_files_in_image_folder = os.listdir(IMAGE_FOLDER)\n",
    "\n",
    "    # keep only the .jpg files (filter out the /mask folder)\n",
    "    image_filenames = [f for f in all_files_in_image_folder if f.lower().endswith('.jpg')]\n",
    "\n",
    "    # sort the filenames numerically \n",
    "    # since our files aren't formatted such as 001, 002 if we keep them this way 100 will be before 2 \n",
    "    def sort_key(filename):\n",
    "        match = re.match(r'(\\d+)\\.jpg', filename, re.IGNORECASE) # find number (digits) before the extension\n",
    "        return int(match.group(1))\n",
    "    image_filenames.sort(key=sort_key)\n",
    "\n",
    "    # make sure we have 250 files loaded so far\n",
    "    files_to_load = image_filenames[:EXPECTED_TRAINING_FILES]\n",
    "    if len(files_to_load) < EXPECTED_TRAINING_FILES:\n",
    "         print(f\"Warning: Loading {len(files_to_load)} files.\")\n",
    "    else:\n",
    "         print(f\"Loading the {len(files_to_load)} files based on sorted filenames.\")\n",
    "\n",
    "    for img_filename in tqdm(files_to_load, desc=\"Processing Files\"):\n",
    "\n",
    "        # getting the name that will serve as ID as well\n",
    "        image_id = os.path.splitext(img_filename)[0]\n",
    "\n",
    "        # creating full path to the image file\n",
    "        image_path = os.path.join(IMAGE_FOLDER, img_filename)\n",
    "\n",
    "        # finding expected filename for the corresponding mask.\n",
    "        mask_filename = \"binary_\" + image_id + MASK_FILE_EXTENSION # e.g., \"binary_1.tif\"\n",
    "        # creating full path to the mask file\n",
    "        mask_path = os.path.join(MASK_FOLDER, mask_filename)\n",
    "        \n",
    "        # load the image using OpenCV (BGR format by default in OpenCV)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"  Warning: Could not read image file: '{image_path}'. Skipping this pair.\") # check if loading works\n",
    "            continue \n",
    "\n",
    "        # load the mask as Grayscale (single channel) using OpenCV\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            print(f\"  Warning: Could not read mask file: '{mask_path}'. Skipping this pair.\") # check if loading worked.\n",
    "            continue\n",
    "\n",
    "        # finallt, store the loaded data in our list.\n",
    "        data_item = {\n",
    "            'id': image_id,        # The identifier (e.g., '1', '123')\n",
    "            'image': image,        # The loaded image \n",
    "            'mask': mask           # The loaded mask (corresponding to the image)\n",
    "        }\n",
    "        training_data.append(data_item)\n",
    "\n",
    "    print(f\"\\nFinished loading. Successfully loaded {len(training_data)} image/mask pairs.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Error in paths\")\n",
    "    training_data = [] # Ensure data list is empty if loading failed\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred\")\n",
    "    print(e)\n",
    "    training_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1834e9e",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b86beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting feature extraction for 249 items...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c1c5691ee84876a13f170350fec605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting Features:   0%|          | 0/249 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'image_bgr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m tqdm(training_data, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting Features\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m      6\u001b[0m     image_id_str \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 7\u001b[0m     image_bgr_arr \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_bgr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m     mask_grayscale_arr \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask_grayscale\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# 1st step : convert BGR image to RGB\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'image_bgr'"
     ]
    }
   ],
   "source": [
    "all_extracted_features = []\n",
    "\n",
    "if training_data: # if data loaded correctly \n",
    "    for item in tqdm(training_data, desc=\"Extracting Features\"):\n",
    "        image_id_str = item['id']\n",
    "        image_bgr_arr = item['image_bgr']\n",
    "        mask_grayscale_arr = item['mask_grayscale']\n",
    "\n",
    "        # 1st step : convert BGR image to RGB\n",
    "        image_rgb_arr = cv2.cvtColor(image_bgr_arr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 2nd step : binarize the grayscale mask\n",
    "        # _, mask_binary_arr = cv2.threshold(mask_grayscale_arr, 127, 1, cv2.THRESH_BINARY)\n",
    "        mask_binary_arr = (mask_grayscale_arr > 0).astype(np.uint8)\n",
    "        # mask_binary_arr = (mask_grayscale_arr == 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        # 3rd step : extract features\n",
    "        features = extract_features_for_image(image_id_str, image_rgb_arr, mask_binary_arr)\n",
    "        if features:\n",
    "            all_extracted_features.append(features)\n",
    "\n",
    "    # Convert list of feature to a pandas df\n",
    "    features_df = pd.DataFrame(all_extracted_features)\n",
    "\n",
    "    print(\"--- Extracted Features (First 5 rows) ---\")\n",
    "    print(features_df.head())\n",
    "\n",
    "    # features_df.to_csv(\"extracted_bee_project_features.csv\", index=False)\n",
    "\n",
    "else:\n",
    "    print(\"No data loaded, skipping feature extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4e06b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
